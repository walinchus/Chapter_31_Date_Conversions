
import scraperwiki
import xlrd


import datetime           
def cellval(cell, datemode):
    if cell.ctype == xlrd.XL_CELL_DATE:
        datetuple = xlrd.xldate_as_tuple(cell.value, datemode)
        if datetuple[3:] == (0, 0, 0):
            return datetime.date(datetuple[0], datetuple[1], datetuple[2])
        return datetime.date(datetuple[0], datetuple[1], datetuple[2], datetuple[3], datetuple[4], datetuple[5])
    if cell.ctype == xlrd.XL_CELL_EMPTY:    return None
    if cell.ctype == xlrd.XL_CELL_BOOLEAN:  return cell.value == 1
    return cell.value

#set a variable for the spreadsheet location
XLS = 'http://webarchive.nationalarchives.gov.uk/20130402145952/http://transparency.dh.gov.uk/files/2012/10/DailySR-Pub-file-WE-11-11-123.xls'
#use the scrape function on that spreadsheet to create a new variable
xlbin = scraperwiki.scrape(XLS)
#use the open_workbook function on that new variable to create another
book = xlrd.open_workbook(file_contents=xlbin)
sheetstotal = book.nsheets

id = 0
sheetsrange = range(0,sheetstotal)
for sheetnum in sheetsrange:
  print "scraping sheet ", sheetnum
  #use the sheet_by_index method to open the first (0) sheet in variable 'book' - and put it into new variable 'sheet'
  sheet = book.sheet_by_index(sheetnum)
  #use the row_values method and index (1) to grab the second row of 'sheet', and put all cells into the list variable 'title'
  title = sheet.row_values(1)
    #print the string "Title:", followed by the third item (column) in the variable 'title' 
  print "Title:", title[2]
  sheettitle = str(title[2])
  print "sheet.name", sheet.name
  sheetname = sheet.name
    #put cells from the 15th row into 'keys' variable 
  keys = []
  for cell in sheet.row(14):
    keys.append(str(cellval(cell,book.datemode)))
  record = {}
    #loop through a range - from the 16th item (15) to a number generated by using the .nrows method on 'sheet' (to find number of rows in that sheet)
    #put each row number in 'rownumber' as you loop
    print [ cellval(c, book.datemode) for c in sheet.row(14) ]
  for rownumber in range(15, sheet.nrows):
    print rownumber
    for column in range(1,sheet.ncols):
    record[keys[column]] = sheet.row_values(rownumber)[column]
    record['title'] = title[2]
    id+=1
    record['id'] = id
    print "---", record
scraperwiki.sqlite.save(['id'], record)
